{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22c08850-5372-4af6-b6f1-5d9e04bfd771",
      "metadata": {
        "id": "22c08850-5372-4af6-b6f1-5d9e04bfd771"
      },
      "source": [
        "Group Project : Sentiment Analysis on Amazon Reviews\n",
        "\n",
        "Group Members : Jay Gondalia (1196220)\n",
        "                \n",
        "                Zeel Parekh (1196109)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ccc9098-6e7b-4c31-8404-d350e8097681",
      "metadata": {
        "id": "4ccc9098-6e7b-4c31-8404-d350e8097681"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "!pip install textblob\n",
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "775029f4-b94c-46dd-8b4c-95894cbed1ab",
      "metadata": {
        "id": "775029f4-b94c-46dd-8b4c-95894cbed1ab"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import spacy\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "\n",
        "from warnings import filterwarnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from textblob import Word, TextBlob\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"vader_lexicon\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cd64a1-7b03-43df-b919-5e4f0531bcf9",
      "metadata": {
        "id": "88cd64a1-7b03-43df-b919-5e4f0531bcf9"
      },
      "outputs": [],
      "source": [
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d97de1d-320c-43c9-8342-8f2d94133fd2",
      "metadata": {
        "id": "0d97de1d-320c-43c9-8342-8f2d94133fd2"
      },
      "outputs": [],
      "source": [
        "# Load the dataset using Python\n",
        "\n",
        "df = pd.read_csv('amazon_reviews.csv', nrows=2100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d5748e-3647-4c7f-a49a-6a248e4ba776",
      "metadata": {
        "id": "f4d5748e-3647-4c7f-a49a-6a248e4ba776"
      },
      "outputs": [],
      "source": [
        "# Visualization of the Dataset Features\n",
        "# Remove NaN values from the 'reviewText' column\n",
        "df = df.dropna(subset=['reviewText'])\n",
        "\n",
        "# Calculate the length of each reviewText, handling NaN values\n",
        "df['reviewText_length'] = df['reviewText'].apply(lambda x: len(x) if isinstance(x, str) else np.nan)\n",
        "\n",
        "\n",
        "# Histogram of title lengths\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['reviewText_length'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of ReviewText length Lengths')\n",
        "plt.xlabel('ReviewText length Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Visualization of NLP Results\n",
        "# let's visualize the frequency of named entities\n",
        "named_entities_count = df['reviewText'].apply(len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a7b922-b494-4996-8cef-0662337c0221",
      "metadata": {
        "id": "e4a7b922-b494-4996-8cef-0662337c0221"
      },
      "outputs": [],
      "source": [
        "# Load SpaCy model\n",
        "nlp = spacy.load('en_core_web_lg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74aa7b72-9dce-4fce-b746-72434202c486",
      "metadata": {
        "id": "74aa7b72-9dce-4fce-b746-72434202c486"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def text_preprocessing(df, reviewText):\n",
        "    # Normalizing Case Folding - Uppercase to Lowercase\n",
        "    df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "\n",
        "    # Removing Punctuation\n",
        "    df['reviewText'] = df['reviewText'].str.replace('[^\\w\\s]', '')\n",
        "\n",
        "    # Removing Numbers\n",
        "    df['reviewText'] = df['reviewText'].str.replace('\\d', '')\n",
        "\n",
        "    # StopWords\n",
        "    sw = stopwords.words('english')\n",
        "    df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
        "\n",
        "    # Remove Rare Words\n",
        "    temp_df = pd.Series(' '.join(df['reviewText']).split()).value_counts()\n",
        "    drops = temp_df[temp_df <= 1]\n",
        "    df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in drops))\n",
        "\n",
        "    # Lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    df['reviewText'] = df['reviewText'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a370c8-918c-480d-a8f7-bdc9ec2112dd",
      "metadata": {
        "id": "77a370c8-918c-480d-a8f7-bdc9ec2112dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = text_preprocessing(df, \"reviewText\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d054967-92e3-4011-8ebf-c772276cb00f",
      "metadata": {
        "id": "6d054967-92e3-4011-8ebf-c772276cb00f"
      },
      "source": [
        "Method 1: SpaCy Word Embeddings :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "046958de-3633-443b-ac1c-1118f0643fa2",
      "metadata": {
        "id": "046958de-3633-443b-ac1c-1118f0643fa2"
      },
      "outputs": [],
      "source": [
        "# Working with Word Vectors\n",
        "def generate_word_vectors(reviewText):\n",
        "    doc = nlp(reviewText)\n",
        "    return [token.vector for token in doc]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e58887-55a8-4e8d-b885-0b13938a868a",
      "metadata": {
        "id": "a3e58887-55a8-4e8d-b885-0b13938a868a"
      },
      "outputs": [],
      "source": [
        "# Apply SpaCy for word vector generation to the title column\n",
        "df['word_vectors_reviewText'] = df['reviewText'].apply(generate_word_vectors)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39c9ec21-d3cd-4ac0-bf67-a12b397a72b4",
      "metadata": {
        "id": "39c9ec21-d3cd-4ac0-bf67-a12b397a72b4"
      },
      "outputs": [],
      "source": [
        "# Display vectors\n",
        "for i, vector_list in enumerate(df['word_vectors_reviewText']):\n",
        "    print(f\"Word vectors for reviewText {i + 1}:\", vector_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d4255d-0bdc-46c2-8441-d00e7ddf8caa",
      "metadata": {
        "id": "04d4255d-0bdc-46c2-8441-d00e7ddf8caa"
      },
      "outputs": [],
      "source": [
        "# Syntax and Structure Analysis\n",
        "def construct_syntax_trees(reviewText):\n",
        "    doc = nlp(reviewText)\n",
        "    trees = [sent.root for sent in doc.sents]\n",
        "    return trees\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a36d760-1c60-4755-95af-3d057ea1d940",
      "metadata": {
        "id": "3a36d760-1c60-4755-95af-3d057ea1d940"
      },
      "outputs": [],
      "source": [
        "# Apply SpaCy for syntax tree construction to the title column\n",
        "df['syntax_trees_reviewText'] = df['reviewText'].apply(construct_syntax_trees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33179add-fbf9-46df-bd42-73e9f6ce673d",
      "metadata": {
        "id": "33179add-fbf9-46df-bd42-73e9f6ce673d"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "def visualize_nlp_results(reviewText):\n",
        "    doc = nlp(reviewText)\n",
        "\n",
        "    # Visualize named entities, dependency parse, and custom patterns\n",
        "    displacy.render(doc, style='ent')\n",
        "    displacy.render(doc, style='dep')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f97288d-83a0-49ea-a8f2-8aad371b5f4f",
      "metadata": {
        "id": "3f97288d-83a0-49ea-a8f2-8aad371b5f4f"
      },
      "outputs": [],
      "source": [
        "# Visualize named entities, dependency parse, and custom patterns for the title column\n",
        "df['reviewText'].apply(visualize_nlp_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358f8329-5683-480b-b85a-8a3bee6d0873",
      "metadata": {
        "id": "358f8329-5683-480b-b85a-8a3bee6d0873"
      },
      "outputs": [],
      "source": [
        "def text_visulaization(df, reviewText, wordcloud=True):\n",
        "  # Calculation of Term Frequencies\n",
        "\n",
        "  tf = df['reviewText'].str.split(expand=True).stack().value_counts().reset_index()\n",
        "  tf.columns = [\"words\", \"tf\"]\n",
        "\n",
        "  if wordcloud:\n",
        "    # WordCloud\n",
        "    text = \" \".join(i for i in df['reviewText'])\n",
        "    wordcloud = WordCloud(max_font_size=100, max_words=1000, background_color=\"white\").generate(text)\n",
        "    plt.figure(figsize=[10, 10])\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Calculation of Term Frequencies : wordcloud\")\n",
        "    plt.show()\n",
        "    wordcloud.to_file(\"wordcloud.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "353fc6de-b046-4eb8-be9b-56f28596309a",
      "metadata": {
        "id": "353fc6de-b046-4eb8-be9b-56f28596309a"
      },
      "outputs": [],
      "source": [
        "text_visulaization(df, \"reviewText\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "524861e5-d5fc-43ab-b9c5-150bac274b94",
      "metadata": {
        "id": "524861e5-d5fc-43ab-b9c5-150bac274b94"
      },
      "outputs": [],
      "source": [
        "def create_polarity_scores(df, reviewText):\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "  df[\"polarity_score\"] = df['reviewText'].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
        "\n",
        "create_polarity_scores(df, \"reviewText\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b2e3ae-3776-41f6-a34d-cb3e280469af",
      "metadata": {
        "id": "44b2e3ae-3776-41f6-a34d-cb3e280469af"
      },
      "outputs": [],
      "source": [
        "# Create Lables\n",
        "def create_label(df, reviewText, sentiment_label):\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "  df['sentiment_label'] = df['reviewText'].apply(lambda x: \"pos\" if sia.polarity_scores(x)[\"compound\"] > 0 else \"neg\")\n",
        "  df['sentiment_label'] = LabelEncoder().fit_transform(df['sentiment_label'])\n",
        "\n",
        "  X = df['reviewText']\n",
        "  y = df['sentiment_label']\n",
        "\n",
        "  return X, y\n",
        "X, y = create_label(df, \"reviewText\", \"sentiment_label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d231bede-5f73-40dc-bf81-d2e9dc77c458",
      "metadata": {
        "id": "d231bede-5f73-40dc-bf81-d2e9dc77c458"
      },
      "outputs": [],
      "source": [
        "# Split Dataset\n",
        "def split_dataset(dataframe, X, y):\n",
        "  train_x, test_x, train_y, test_y = train_test_split(X, y, random_state=1)\n",
        "  return train_x, test_x, train_y, test_y\n",
        "\n",
        "train_x, test_x, train_y, test_y = split_dataset(df, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "490575fe-4bf0-43fb-915f-0444d20918a9",
      "metadata": {
        "id": "490575fe-4bf0-43fb-915f-0444d20918a9"
      },
      "outputs": [],
      "source": [
        "def create_features_count(train_x, test_x):\n",
        "  # Count Vectors\n",
        "  vectorizer = CountVectorizer()\n",
        "  x_train_count_vectorizer = vectorizer.fit_transform(train_x)\n",
        "  x_test_count_vectorizer = vectorizer.fit_transform(test_x)\n",
        "\n",
        "  return x_train_count_vectorizer, x_test_count_vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a4e985-4f04-4243-ba34-0a2d0c4f6038",
      "metadata": {
        "id": "c0a4e985-4f04-4243-ba34-0a2d0c4f6038"
      },
      "outputs": [],
      "source": [
        "x_train_count_vectorizer, x_test_count_vectorizer = create_features_count(train_x, test_x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f0101c-1672-4796-8b38-723f17be290a",
      "metadata": {
        "id": "89f0101c-1672-4796-8b38-723f17be290a"
      },
      "source": [
        "Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9ad90c-c866-44bc-8632-9680d8fff19f",
      "metadata": {
        "id": "5b9ad90c-c866-44bc-8632-9680d8fff19f"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "def crate_model_logistic(train_x, test_x):\n",
        "  # Count\n",
        "  x_train_count_vectorizer, x_test_count_vectorizer = create_features_count(train_x, test_x)\n",
        "  loj_count = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "  loj_model_count = loj_count.fit(x_train_count_vectorizer, train_y)\n",
        "  accuracy_count = cross_val_score(loj_model_count, x_test_count_vectorizer, test_y, cv=10).mean()\n",
        "  print(\"Accuracy - Count Vectors: %.3f\" % accuracy_count)\n",
        "\n",
        "  return loj_model_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3667eb6-7807-4c9f-bfb3-d917ef0a8d2d",
      "metadata": {
        "id": "b3667eb6-7807-4c9f-bfb3-d917ef0a8d2d"
      },
      "outputs": [],
      "source": [
        "\n",
        "loj_model_count = crate_model_logistic(train_x, test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50e4f790-d9f9-4dd0-bc04-5f6f76918750",
      "metadata": {
        "id": "50e4f790-d9f9-4dd0-bc04-5f6f76918750"
      },
      "outputs": [],
      "source": [
        "def crate_model_randomforest(train_x, test_x):\n",
        "  # Count\n",
        "  x_train_count_vectorizer, x_test_count_vectorizer = create_features_count(train_x, test_x)\n",
        "  rf_count = RandomForestClassifier()\n",
        "  rf_model_count = rf_count.fit(x_train_count_vectorizer, train_y)\n",
        "  accuracy_count = cross_val_score(rf_model_count, x_test_count_vectorizer, test_y, cv=10).mean()\n",
        "  print(\"Accuracy - Count Vectors: %.3f\" % accuracy_count)\n",
        "\n",
        "  return rf_model_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256d0209-5373-4572-bcd2-0e715db0225d",
      "metadata": {
        "id": "256d0209-5373-4572-bcd2-0e715db0225d"
      },
      "outputs": [],
      "source": [
        "\n",
        "rf_model_count = crate_model_randomforest(train_x, test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebaa2ac5-9d0f-4181-85b9-454ac4dee5dc",
      "metadata": {
        "id": "ebaa2ac5-9d0f-4181-85b9-454ac4dee5dc"
      },
      "outputs": [],
      "source": [
        "def model_tuning_randomforest(train_x, test_x):\n",
        "  # Count\n",
        "  x_train_count_vectorizer, x_test_count_vectorizer = create_features_count(train_x, test_x)\n",
        "  rf_model_count = RandomForestClassifier(random_state=1)\n",
        "  rf_params = {\n",
        "        \"max_depth\": [2, 5, 8, None],\n",
        "        \"max_features\": [2, 5, 8, \"sqrt\", \"log2\"],\n",
        "        \"n_estimators\": [100, 500, 1000],\n",
        "        \"min_samples_split\": [2, 5, 10]\n",
        "    }\n",
        "\n",
        "  rf_best_grid = GridSearchCV(rf_model_count, rf_params, cv=10, n_jobs=-1, verbose=False).fit(x_train_count_vectorizer, train_y)\n",
        "  rf_model_count_final = rf_model_count.set_params(**rf_best_grid.best_params_, random_state=1).fit(x_train_count_vectorizer, train_y)\n",
        "  accuracy_count = cross_val_score(rf_model_count_final, x_test_count_vectorizer, test_y, cv=10).mean()\n",
        "  print(\"Accuracy - Count Vectors: %.3f\" % accuracy_count)\n",
        "\n",
        "  return rf_model_count_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e06de7-1ae6-4d57-bc6c-de9d027869b4",
      "metadata": {
        "id": "74e06de7-1ae6-4d57-bc6c-de9d027869b4"
      },
      "outputs": [],
      "source": [
        "rf_model_count_final = model_tuning_randomforest(train_x, test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3816731-c422-46d2-af0a-8361cdce2363",
      "metadata": {
        "id": "d3816731-c422-46d2-af0a-8361cdce2363"
      },
      "outputs": [],
      "source": [
        "def predict_count(train_x, model, new_comment):\n",
        "  new_comment= pd.Series(new_comment)\n",
        "  new_comment = CountVectorizer().fit(train_x).transform(new_comment)\n",
        "  result = model.predict(new_comment)\n",
        "  if result==1:\n",
        "    print(\"Comment is Positive\")\n",
        "  else:\n",
        "    print(\"Comment is Negative\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ecf923-3024-4c34-8a15-06b13ce76345",
      "metadata": {
        "id": "53ecf923-3024-4c34-8a15-06b13ce76345"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "predict_count(train_x, model=loj_model_count, new_comment=\"this product is very good but i hate it :)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd2d617-e7b4-4a75-a011-e1970eb55f17",
      "metadata": {
        "id": "6dd2d617-e7b4-4a75-a011-e1970eb55f17"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "predict_count(train_x, model=rf_model_count, new_comment=\"this product is very bad :)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e7f6c9-28b1-4328-a260-5ca22c11a6b2",
      "metadata": {
        "id": "84e7f6c9-28b1-4328-a260-5ca22c11a6b2"
      },
      "outputs": [],
      "source": [
        "# Sample Review\n",
        "# new_comment=pd.Series(df[\"reviewText\"].sample(1).values)\n",
        "print(len(df[\"reviewText\"]))\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    new_comment = row[\"reviewText\"]\n",
        "    print(\"\\n\",new_comment)\n",
        "    # Review - Random Forest\n",
        "    predict_count(train_x, model=rf_model_count, new_comment=new_comment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a008e03a-f86b-451d-b109-a1c28540958f",
      "metadata": {
        "id": "a008e03a-f86b-451d-b109-a1c28540958f"
      },
      "outputs": [],
      "source": [
        "# Importing SVM classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Function to create SVM model\n",
        "def create_model_svm(train_x, test_x):\n",
        "    # Count Vectors\n",
        "    x_train_count_vectorizer, x_test_count_vectorizer = create_features_count(train_x, test_x)\n",
        "\n",
        "    # Initialize SVM classifier\n",
        "    svm_model = SVC(kernel='linear')\n",
        "    svm_model.fit(x_train_count_vectorizer, train_y)\n",
        "\n",
        "    # Calculate accuracy using cross-validation\n",
        "    accuracy_count = cross_val_score(svm_model, x_test_count_vectorizer, test_y, cv=10).mean()\n",
        "    print(\"Accuracy - Count Vectors (SVM): %.3f\" % accuracy_count)\n",
        "\n",
        "    return svm_model\n",
        "\n",
        "# Create SVM model\n",
        "svm_model_count = create_model_svm(train_x, test_x)\n",
        "\n",
        "# Function for SVM model tuning\n",
        "def model_tuning_svm(train_x, test_x):\n",
        "    # Count Vectors\n",
        "    x_train_count_vectorizer, x_test_count_vectorizer = create_features_count(train_x, test_x)\n",
        "\n",
        "    # Initialize SVM classifier\n",
        "    svm_model = SVC(kernel='linear')\n",
        "\n",
        "    # Define parameters for grid search\n",
        "    svm_params = {'C': [0.1, 1, 10, 100],\n",
        "                  'gamma': [1, 0.1, 0.01, 0.001],\n",
        "                  'kernel': ['linear', 'rbf']}\n",
        "\n",
        "    # Perform grid search\n",
        "    svm_best_grid = GridSearchCV(svm_model, svm_params, cv=10, n_jobs=-1, verbose=False)\n",
        "    svm_best_grid.fit(x_train_count_vectorizer, train_y)\n",
        "\n",
        "    # Fit SVM model with best parameters\n",
        "    svm_model_final = svm_model.set_params(**svm_best_grid.best_params_).fit(x_train_count_vectorizer, train_y)\n",
        "\n",
        "    # Calculate accuracy using cross-validation\n",
        "    accuracy_count = cross_val_score(svm_model_final, x_test_count_vectorizer, test_y, cv=10).mean()\n",
        "    print(\"Accuracy - Count Vectors (SVM - Tuned): %.3f\" % accuracy_count)\n",
        "\n",
        "    return svm_model_final\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f66c6ee-3490-4f61-a622-0c296c7be5c9",
      "metadata": {
        "id": "8f66c6ee-3490-4f61-a622-0c296c7be5c9"
      },
      "outputs": [],
      "source": [
        "# Tune SVM model\n",
        "svm_model_count_final = model_tuning_svm(train_x, test_x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8775767f-f82f-44e1-8bf7-dfb90509a067",
      "metadata": {
        "id": "8775767f-f82f-44e1-8bf7-dfb90509a067"
      },
      "outputs": [],
      "source": [
        "# Prediction function for SVM model\n",
        "def predict_count_svm(train_x, model, new_comment):\n",
        "    new_comment = pd.Series(new_comment)\n",
        "    new_comment = CountVectorizer().fit(train_x).transform(new_comment)\n",
        "    result = model.predict(new_comment)\n",
        "    if result == 1:\n",
        "        print(\"Comment is Positive\")\n",
        "    else:\n",
        "        print(\"Comment is Negative\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3111d3f0-831e-4d66-a7ad-bc5cac7a218e",
      "metadata": {
        "id": "3111d3f0-831e-4d66-a7ad-bc5cac7a218e"
      },
      "outputs": [],
      "source": [
        "# Sample Review - SVM\n",
        "print(new_comment)\n",
        "predict_count_svm(train_x, model=svm_model_count_final, new_comment=new_comment)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8a00573-2e40-4711-98cd-06e4981155b3",
      "metadata": {
        "id": "c8a00573-2e40-4711-98cd-06e4981155b3"
      },
      "source": [
        "NLP SPACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7579d82-36f7-4dfa-94f3-5d344f8c304e",
      "metadata": {
        "id": "b7579d82-36f7-4dfa-94f3-5d344f8c304e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from spacy.pipeline.textcat import Config, single_label_cnn_config\n",
        "from spacy.training.example import Example\n",
        "from spacy.util import minibatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9ff797-3187-48ac-8bf6-b7cdf49290a9",
      "metadata": {
        "id": "2e9ff797-3187-48ac-8bf6-b7cdf49290a9"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "#Add  the  TextCategorizer  to  the  pipeline\n",
        "if 'textcat' not in nlp.pipe_names:\n",
        "    textcat = nlp.add_pipe('textcat', last=True)\n",
        "else:\n",
        "    textcat = nlp.get_pipe('textcat')\n",
        "\n",
        "unique_labels = ['Pozitive','Negative']\n",
        "\n",
        "for label in unique_labels:\n",
        "    textcat.add_label(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29697f91-4abc-43da-9d41-32345723a7ea",
      "metadata": {
        "id": "29697f91-4abc-43da-9d41-32345723a7ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "def df_to_spacy_format(df):\n",
        "    new_data = []\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['reviewText']\n",
        "\n",
        "\n",
        "        # Initialize default_cats with zeros for both labels\n",
        "        default_cats = {'Pozitive': 0, 'Negative': 0}\n",
        "\n",
        "        # Set the value corresponding to the sentiment label to 1\n",
        "        sentiment_label = 'Pozitive' if row['sentiment_label'] == 1 else 'Negative'\n",
        "        default_cats[sentiment_label] = 1\n",
        "\n",
        "        # Construct the cats_dict with the updated default_cats\n",
        "        cats_dict = {\"cats\": default_cats}\n",
        "\n",
        "        new_data.append((text, cats_dict))\n",
        "    return new_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e6cbc8-0b50-42a4-8188-2fea33a29602",
      "metadata": {
        "id": "23e6cbc8-0b50-42a4-8188-2fea33a29602"
      },
      "outputs": [],
      "source": [
        "# Feed  dataframe into the above function\n",
        "# Feed here\n",
        "new_data = df_to_spacy_format(df)\n",
        "\n",
        "#Print the new data\n",
        "for text, cats_dict in new_data:\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Categories: {cats_dict['cats']}\")\n",
        "    print(\"----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0fa7cb-9da7-4c98-a80e-d16842dc4517",
      "metadata": {
        "id": "3c0fa7cb-9da7-4c98-a80e-d16842dc4517"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(new_data)\n",
        "\n",
        "# Print the new data after shuffle\n",
        "for text, cats_dict in new_data:\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Categories: {cats_dict['cats']}\")\n",
        "    print(\"----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f33fe9d-4828-4f7c-adae-6555a59e2319",
      "metadata": {
        "id": "8f33fe9d-4828-4f7c-adae-6555a59e2319"
      },
      "outputs": [],
      "source": [
        "# in the training dataset\n",
        "train_size = int(0.7 * len(new_data))\n",
        "\n",
        "# Split the list into two parts\n",
        "train_data = new_data[:train_size]\n",
        "test_data = new_data[train_size:]\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ef616c-aa87-4928-971b-3b987a653997",
      "metadata": {
        "id": "41ef616c-aa87-4928-971b-3b987a653997"
      },
      "outputs": [],
      "source": [
        "def nn_spacy(num_epochs, batch_size, data_train):\n",
        "\n",
        "    # Training the text categorization model\n",
        "    optimizer = nlp.initialize()\n",
        "    tot_loss = []\n",
        "    for epoch in range(num_epochs):  # Number of training epochs\n",
        "        losses = {}\n",
        "        batches = minibatch(data_train, size=batch_size)\n",
        "        for batch in batches:\n",
        "            examples = [Example.from_dict(nlp.make_doc(text), annotations) for text, annotations in batch]\n",
        "            nlp.update(examples, drop=0.2, losses=losses, sgd=optimizer)\n",
        "        print(losses['textcat'])\n",
        "        tot_loss.append(losses['textcat'])\n",
        "\n",
        "    return tot_loss, nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b67039-42ec-44b1-b2a7-a1b88a4312b2",
      "metadata": {
        "id": "a3b67039-42ec-44b1-b2a7-a1b88a4312b2"
      },
      "outputs": [],
      "source": [
        "## Train the neural network with these hyper parameters and plot loss during the training\n",
        "#number of epochs: 4 and batch size : 4\n",
        "num_epochs = 4\n",
        "tot_loss1, nlp1 = nn_spacy(num_epochs,10,train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9145a587-1b57-4028-a3dc-6351c8737964",
      "metadata": {
        "id": "9145a587-1b57-4028-a3dc-6351c8737964"
      },
      "outputs": [],
      "source": [
        "# Plot loss during training\n",
        "plt.plot(range(1, num_epochs + 1), tot_loss1, marker='o')\n",
        "plt.title('Loss During Training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(range(1, num_epochs + 1))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa837751-d791-4a3e-8ecc-93d3f3b29eca",
      "metadata": {
        "id": "fa837751-d791-4a3e-8ecc-93d3f3b29eca"
      },
      "outputs": [],
      "source": [
        "def find_marked_categories(cat_dict):\n",
        "    marked_categories = [category for category, value in cat_dict['cats'].items() if value == 1]\n",
        "    return marked_categories[0]\n",
        "\n",
        "\n",
        "def predict_and_evaluate(model, test_data):\n",
        "    correct_predictions = 0\n",
        "    predictions = []\n",
        "\n",
        "    for text, true_labels in test_data:\n",
        "        doc = model(text)\n",
        "        prediction = doc.cats\n",
        "\n",
        "        highest_category = max(prediction, key=prediction.get)\n",
        "        if find_marked_categories(true_labels) == highest_category:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    return correct_predictions/len(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "488fa6ac-4bcf-429c-9ea9-24ebd2626f94",
      "metadata": {
        "id": "488fa6ac-4bcf-429c-9ea9-24ebd2626f94"
      },
      "outputs": [],
      "source": [
        "predict_and_evaluate(nlp1,test_data)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}